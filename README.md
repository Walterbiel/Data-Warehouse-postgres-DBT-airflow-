
# Live Data Warehouse (PostgreSQL, dbt & Airflow)

Em parceria com a **3D Universe Creators** ‚Äî sorteio de logos em impress√£o 3D de Power BI e Python

## üí° Recomendado para Windows
Se estiver usando Windows, o melhor cen√°rio √©:

Usar o WSL2 (Subsistema Linux do Windows) com uma distro como Ubuntu.

Voc√™ roda tudo como se estivesse em um Linux real, incluindo Docker, dbt, Airflow, PostgreSQL e VS Code com integra√ß√£o total.

---

## Vis√£o Geral

Este projeto demonstra a constru√ß√£o de um **Data Warehouse** completo utilizando **PostgreSQL** como banco relacional, **dbt** para transforma√ß√£o de dados e **Apache Airflow** para orquestra√ß√£o de pipelines. O objetivo √© atender √†s necessidades de integra√ß√£o, tratamento, an√°lise e visualiza√ß√£o de dados para √°reas de vendas, estoque e produ√ß√£o.

---

## Requisitos de Neg√≥cio

1. **Coleta e Integra√ß√£o de Dados**  
   - Integra√ß√£o autom√°tica com sistemas ERP para capturar tabelas de vendas, estoque e ordens de produ√ß√£o, com atualiza√ß√£o di√°ria ou em tempo real.  
   - Tratamento e padroniza√ß√£o (nomes de produtos, datas, filiais, centros de custo).  
   - Armazenamento em estrutura anal√≠tica (Data Warehouse ou Lakehouse).

2. **An√°lises Essenciais**  
   - Resumo di√°rio de vendas (quantidade, faturamento, ticket m√©dio por loja, canal e produto).  
   - Ruptura e giro de estoque (estoque zerado, tempo m√©dio de reposi√ß√£o, giro por categoria).  
   - Status da produ√ß√£o (ordens em aberto, em atraso, produ√ß√£o por linha/f√°brica).  
   - Comparativo Real √ó Meta (metas comerciais por equipe, linha de produto e per√≠odo).  
   - Alertas operacionais para desvios em vendas, estoque ou produ√ß√£o.

3. **Visualiza√ß√£o e A√ß√µes**  
   - Dashboard unificado com pain√©is interativos para vendas, estoque e produ√ß√£o, acess√≠vel em desktop e mobile.  
   - Filtros din√¢micos por per√≠odo, filial, produto, categoria e canal.  
   - Alertas automatizados (e-mail/WhatsApp) para eventos cr√≠ticos.  
   - Exporta√ß√£o de relat√≥rios (Excel/PDF) para reuni√µes estrat√©gicas.

---

## Como Come√ßar

### 1. Prepara√ß√£o do Projeto

```bash

# Crie um ambiente virtual
python3.11 -m venv .venv
source .venv/bin/activate

pip install --upgrade pip
pip install -r requirements.txt

```

### 2. Gerar uma chave para criptografia (opcional para dbt)

```bash
python -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())"
```

### 3. Crie as pastas necess√°rias

```bash
mkdir -p  logs plugins dbt
```
#### 4. Gerar dados fake e subir dados para o postgres

# Scripts DDL ‚Äì Camada **bronze**

> **Execute** estes comandos no PostgreSQL antes da ingest√£o.  
> Cada tabela recebe uma chave prim√°ria surrogate (`BIGSERIAL`) iniciando em 1.

---

## 1. Criar schema

```sql
CREATE SCHEMA IF NOT EXISTS bronze;
```

---

## 2. Tabela `bronze.vendas`

```sql
CREATE TABLE IF NOT EXISTS bronze.vendas (
    pk_vendas       BIGSERIAL PRIMARY KEY,
    id_venda        BIGINT        NOT NULL,
    id_produto      INTEGER       NOT NULL,
    preco           NUMERIC(12,2) NOT NULL,
    quantidade      INTEGER       NOT NULL,
    data_venda      DATE          NOT NULL,
    id_cliente      INTEGER,
    id_loja         INTEGER,
    id_vendedor     INTEGER,
    meio_pagamento  TEXT,
    parcelamento    SMALLINT
);

CREATE INDEX IF NOT EXISTS idx_vendas_id_venda ON bronze.vendas (id_venda);
CREATE INDEX IF NOT EXISTS idx_vendas_data     ON bronze.vendas (data_venda);
CREATE INDEX IF NOT EXISTS idx_vendas_produto  ON bronze.vendas (id_produto);
```

---

## 3. Tabela `bronze.devolucoes`

```sql
CREATE TABLE IF NOT EXISTS bronze.devolucoes (
    pk_devolucao    BIGSERIAL PRIMARY KEY,
    id_venda        BIGINT    NOT NULL,
    id_produto      INTEGER   NOT NULL,
    preco           NUMERIC(12,2) NOT NULL,
    quantidade      INTEGER   NOT NULL,
    data_venda      DATE      NOT NULL,
    data_devolucao  DATE      NOT NULL,
    id_cliente      INTEGER,
    id_loja         INTEGER,
    id_vendedor     INTEGER,
    motivo          TEXT,
    UNIQUE (id_venda, id_produto)
);

CREATE INDEX IF NOT EXISTS idx_dev_data_devolucao
    ON bronze.devolucoes (data_devolucao);
```

---

## 4. Tabela `bronze.produtos`

```sql
CREATE TABLE IF NOT EXISTS bronze.produtos (
    pk_produto          BIGSERIAL PRIMARY KEY,
    id_produto          INTEGER UNIQUE NOT NULL,
    nome_produto        TEXT    NOT NULL,
    categoria           TEXT,
    percentual_imposto  NUMERIC(5,2)
);
```

---

## 5. Tabela `bronze.lojas`

```sql
CREATE TABLE IF NOT EXISTS bronze.lojas (
    pk_loja     BIGSERIAL PRIMARY KEY,
    id_loja     INTEGER UNIQUE NOT NULL,
    nome_loja   TEXT    NOT NULL,
    logradouro  TEXT,
    numero      INTEGER,
    bairro      TEXT,
    cidade      TEXT,
    estado      CHAR(2),
    cep         VARCHAR(10)
);
```

---

## 6. Tabela `bronze.vendedores`

```sql
CREATE TABLE IF NOT EXISTS bronze.vendedores (
    pk_vendedor     BIGSERIAL PRIMARY KEY,
    id_vendedor     INTEGER UNIQUE NOT NULL,
    nome_vendedor   TEXT    NOT NULL,
    data_admissao   DATE,
    endereco_vendedor TEXT,
    data_nascimento DATE
);
```
---

# üìÅ Estrutura das Tabelas na Camada Bronze

As seguintes tabelas est√£o dispon√≠veis no banco PostgreSQL, no schema `bronze`:

- `vendas`: informa√ß√µes de vendas realizadas.
- `devolucoes`: registros de devolu√ß√µes de vendas.
- `produtos`: cat√°logo de produtos com categoria e impostos.
- `lojas`: dados cadastrais das lojas.
- `vendedores`: cadastro de vendedores e datas importantes.

---

## üîß Configura√ß√£o do dbt (Data Build Tool)

Este projeto utiliza o **dbt** para organizar e transformar os dados da camada bronze at√© a gold. Abaixo est√£o os passos completos para configura√ß√£o e execu√ß√£o:

### 1. Inicializa√ß√£o do Projeto

```bash
dbt init vendas_dw
```

Siga os prompts e selecione o adaptador `Postgres`.

---

### 2. Estrutura Esperada do Projeto

```text
vendas_dw/
‚îú‚îÄ‚îÄ dbt_project.yml
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ bronze/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ vendas.sql
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ devolucoes.sql
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ produtos.sql
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ lojas.sql
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ vendedores.sql
‚îÇ   ‚îú‚îÄ‚îÄ silver/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ fct_vendas.sql
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ fct_devolucoes.sql
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ dim_lojas.sql
‚îÇ   ‚îú‚îÄ‚îÄ gold/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ indicadores_vendas.sql
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ produtos_mais_devolvidos.sql
‚îÇ   ‚îî‚îÄ‚îÄ _sources.yml
```

---

### 3. Configura√ß√£o do Profile

Crie ou edite o arquivo `~/.dbt/profiles.yml`:

```yaml
vendas_dw:
  target: dev
  outputs:
    dev:
      type: postgres
      host: localhost
      user: seu_usuario
      password: sua_senha
      port: 5432
      dbname: seu_banco
      schema: bronze
      threads: 4
```
bash (mover profile.yml)
```
mkdir -p ~/.dbt
code ~/.dbt/profiles.yml
```

---

### testar a conex√£o:
```
dbt debug --project-dir vendas_dw
```

### 4. Registro de Tabelas de Origem

`models/_sources.yml`:

```yaml
version: 2

sources:
  - name: bronze
    database: seu_banco
    schema: bronze
    tables:
      - name: vendas
      - name: devolucoes
      - name: produtos
      - name: lojas
      - name: vendedores
```

---

### 8. Executando o Projeto

Para compilar e rodar os modelos:

```bash
dbt run
```

Para validar a conex√£o e estrutura:

```bash
dbt debug
```

---

---

## üóÇÔ∏è Estrutura de diret√≥rios

```
models/
‚îú‚îÄ sources.yml               # defini√ß√£o das fontes bronze
‚îú‚îÄ silver/
‚îÇ  ‚îú‚îÄ stg_vendas.sql
‚îÇ  ‚îú‚îÄ stg_devolucoes.sql
‚îÇ  ‚îú‚îÄ dim_produtos.sql
‚îÇ  ‚îú‚îÄ dim_lojas.sql
‚îÇ  ‚îî‚îÄ dim_vendedores.sql
‚îî‚îÄ gold/
   ‚îú‚îÄ fct_vendas.sql
   ‚îú‚îÄ fct_devolucoes.sql
   ‚îú‚îÄ mart_receita_diaria_loja.sql
   ‚îî‚îÄ mart_receita_mensal_categoria.sql
```

> **Materializa√ß√£o**  
> - Todos os modelos usam `{{ config(materialized='table') }}`.  
> - Os *schemas* (**bronze**, **silver**, **gold**) s√£o definidos no `project.yaml`.

---

## 4¬† üöÄ Execu√ß√£o sugerida para a aula

```bash
# 1) Materializar staging
dbt run --select silver

# 2) Materializar fatos e marts
dbt run --select gold

# 3) Explorar lineage
dbt docs generate
dbt docs serve
```

------------------------------------------------------------------------------------------

### Rodar no postgres:

## ‚öôÔ∏è Execu√ß√£o
Execute os comandos abaixo em sua inst√¢ncia PostgreSQL, ajustando os nomes dos schemas e tabelas conforme necess√°rio.

---
## üîπ Queries por Categoria

### üìÇ Transforma√ß√µes de Dimens√µes

#### üßæ dim_lojas.sql

```sql
-- {{ config(materialized = 'table') -- }}

with src as (

    select
        cast(id_loja  as int)   as id_loja,
        nome_loja,
        logradouro,
        cast("numero" as int)   as numero,
        bairro,
        cidade,
        estado,
        cep
    from -- {{ source('bronze','lojas') -- }}

)

select *
from src
```

#### üßæ dim_produtos.sql

```sql
-- {{ config(materialized = 'table') -- }}

with src as (

    select
        cast(id_produto         as int)           as id_produto,
        nome_produto,
        categoria,
        cast(percentual_imposto as numeric(5,2))  as percentual_imposto
    from -- {{ source('bronze','produtos') -- }}

)

select *
from src
```

#### üßæ dim_vendedores.sql

```sql
-- {{ config(materialized = 'table') -- }}

with src as (

    select
        cast(id_vendedor                as int)   as id_vendedor,
        nome_vendedor,
        cast(data_admissao     as date)  as data_admissao,
        endereco_vendedor,
        cast(data_nascimento   as date)  as data_nascimento
    from -- {{ source('bronze','vendedores') -- }}

)

select *
from src
```

### üìÇ Prepara√ß√£o### 3.1¬† `fct_vendas.sql` ‚Äî fluxo simplificado
```mermaid
graph TD
    subgraph Silver
        A(stg_vendas) -->|FK| B(dim_produtos)
        A -->|FK| C(dim_lojas)
        A -->|FK| D(dim_vendedores)
    end
    A -->|JOIN| E(fct_vendas - Gold)
```

### 3.2¬† `mart_receita_diaria_loja.sql`
```sql
select
    data_venda,
    id_loja,
    nome_loja,
    sum(receita_bruta) as receita_diaria,
    count(distinct id_venda) as qtd_vendas,
    sum(quantidade) as itens_vendidos
from {{ ref('fct_vendas') }}
group by data_venda, id_loja, nome_loja;
```
> **Uso**: Pain√©is operacionais (metas di√°rias, comparativo de lojas).
 e Limpeza da Staging

#### üßæ stg_vendas.sql

```sql
-- {{ config(
    materialized = 'incremental',
    unique_key = 'id_venda'
) -- }}

WITH src AS (

    SELECT
        CAST(id_venda       AS BIGINT)        AS id_venda,
        CAST(id_produto     AS INTEGER)       AS id_produto,
        CAST(preco          AS NUMERIC(12,2)) AS preco,
        CAST(quantidade     AS INTEGER)       AS quantidade,
        CAST(data_venda     AS DATE)          AS data_venda,
        CAST(id_cliente     AS INTEGER)       AS id_cliente,
        CAST(id_loja        AS INTEGER)       AS id_loja,
        CAST(id_vendedor    AS INTEGER)       AS id_vendedor,
        LOWER(TRIM(meio_pagamento))           AS meio_pagamento,
        CAST(parc### 3.1¬† `fct_vendas.sql` ‚Äî fluxo simplificado
```mermaid
graph TD
    subgraph Silver
        A(stg_vendas) -->|FK| B(dim_produtos)
        A -->|FK| C(dim_lojas)
        A -->|FK| D(dim_vendedores)
    end
    A -->|JOIN| E(fct_vendas - Gold)
```

### 3.2¬† `mart_receita_diaria_loja.sql`
```sql
select
    data_venda,
    id_loja,
    nome_loja,
    sum(receita_bruta) as receita_diaria,
    count(distinct id_venda) as qtd_vendas,
    sum(quantidade) as itens_vendidos
from {{ ref('fct_vendas') }}
group by data_venda, id_loja, nome_loja;
```
> **Uso**: Pain√©is operacionais (metas di√°rias, comparativo de lojas).
elamento   AS SMALLINT)      AS parcelamento
    FROM -- {{ source('bronze', 'vendas') -- }}
