
# Live Data Warehouse (PostgreSQL, dbt & Airflow)

Em parceria com a **3D Universe Creators** ‚Äî sorteio de logos em impress√£o 3D de Power BI e Python

## üí° Recomendado para Windows
Se estiver usando Windows, o melhor cen√°rio √©:

Usar o WSL2 (Subsistema Linux do Windows) com uma distro como Ubuntu.

Voc√™ roda tudo como se estivesse em um Linux real, incluindo Docker, dbt, Airflow, PostgreSQL e VS Code com integra√ß√£o total.

---

## Vis√£o Geral

Este projeto demonstra a constru√ß√£o de um **Data Warehouse** completo utilizando **PostgreSQL** como banco relacional, **dbt** para transforma√ß√£o de dados e **Apache Airflow** para orquestra√ß√£o de pipelines. O objetivo √© atender √†s necessidades de integra√ß√£o, tratamento, an√°lise e visualiza√ß√£o de dados para √°reas de vendas, estoque e produ√ß√£o.

---

## Requisitos de Neg√≥cio

1. **Coleta e Integra√ß√£o de Dados**  
   - Integra√ß√£o autom√°tica com sistemas ERP para capturar tabelas de vendas, estoque e ordens de produ√ß√£o, com atualiza√ß√£o di√°ria ou em tempo real.  
   - Tratamento e padroniza√ß√£o (nomes de produtos, datas, filiais, centros de custo).  
   - Armazenamento em estrutura anal√≠tica (Data Warehouse ou Lakehouse).

2. **An√°lises Essenciais**  
   - Resumo di√°rio de vendas (quantidade, faturamento, ticket m√©dio por loja, canal e produto).  
   - Ruptura e giro de estoque (estoque zerado, tempo m√©dio de reposi√ß√£o, giro por categoria).  
   - Status da produ√ß√£o (ordens em aberto, em atraso, produ√ß√£o por linha/f√°brica).  
   - Comparativo Real √ó Meta (metas comerciais por equipe, linha de produto e per√≠odo).  
   - Alertas operacionais para desvios em vendas, estoque ou produ√ß√£o.

3. **Visualiza√ß√£o e A√ß√µes**  
   - Dashboard unificado com pain√©is interativos para vendas, estoque e produ√ß√£o, acess√≠vel em desktop e mobile.  
   - Filtros din√¢micos por per√≠odo, filial, produto, categoria e canal.  
   - Alertas automatizados (e-mail/WhatsApp) para eventos cr√≠ticos.  
   - Exporta√ß√£o de relat√≥rios (Excel/PDF) para reuni√µes estrat√©gicas.

---

## Como Come√ßar

### 1. Prepara√ß√£o do Projeto

```bash
# Clone o projeto e entre no diret√≥rio
git clone https://github.com/seu-usuario/seu-projeto.git
cd seu-projeto

# Crie um ambiente virtual
python -m venv .venv
source .venv/bin/activate

# Instale as depend√™ncias
pip install -r requirements.txt
```

### 2. Gerar uma chave para criptografia (opcional para dbt)

```bash
python -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())"
```

### 3. Crie as pastas necess√°rias

```bash
mkdir -p dags logs plugins dbt
```
#### 4. Gerar dados fake e subir dados para o postgres

# Scripts DDL ‚Äì Camada **bronze**

> **Execute** estes comandos no PostgreSQL antes da ingest√£o.  
> Cada tabela recebe uma chave prim√°ria surrogate (`BIGSERIAL`) iniciando em 1.

---

## 1. Criar schema

```sql
CREATE SCHEMA IF NOT EXISTS bronze;
```

---

## 2. Tabela `bronze.vendas`

```sql
CREATE TABLE IF NOT EXISTS bronze.vendas (
    pk_vendas       BIGSERIAL PRIMARY KEY,
    id_venda        BIGINT        NOT NULL,
    id_produto      INTEGER       NOT NULL,
    preco           NUMERIC(12,2) NOT NULL,
    quantidade      INTEGER       NOT NULL,
    data_venda      DATE          NOT NULL,
    id_cliente      INTEGER,
    id_loja         INTEGER,
    id_vendedor     INTEGER,
    meio_pagamento  TEXT,
    parcelamento    SMALLINT
);

CREATE INDEX IF NOT EXISTS idx_vendas_id_venda ON bronze.vendas (id_venda);
CREATE INDEX IF NOT EXISTS idx_vendas_data     ON bronze.vendas (data_venda);
CREATE INDEX IF NOT EXISTS idx_vendas_produto  ON bronze.vendas (id_produto);
```

---

## 3. Tabela `bronze.devolucoes`

```sql
CREATE TABLE IF NOT EXISTS bronze.devolucoes (
    pk_devolucao    BIGSERIAL PRIMARY KEY,
    id_venda        BIGINT    NOT NULL,
    id_produto      INTEGER   NOT NULL,
    preco           NUMERIC(12,2) NOT NULL,
    quantidade      INTEGER   NOT NULL,
    data_venda      DATE      NOT NULL,
    data_devolucao  DATE      NOT NULL,
    id_cliente      INTEGER,
    id_loja         INTEGER,
    id_vendedor     INTEGER,
    motivo          TEXT,
    UNIQUE (id_venda, id_produto)
);

CREATE INDEX IF NOT EXISTS idx_dev_data_devolucao
    ON bronze.devolucoes (data_devolucao);
```

---

## 4. Tabela `bronze.produtos`

```sql
CREATE TABLE IF NOT EXISTS bronze.produtos (
    pk_produto          BIGSERIAL PRIMARY KEY,
    id_produto          INTEGER UNIQUE NOT NULL,
    nome_produto        TEXT    NOT NULL,
    categoria           TEXT,
    percentual_imposto  NUMERIC(5,2)
);
```

---

## 5. Tabela `bronze.lojas`

```sql
CREATE TABLE IF NOT EXISTS bronze.lojas (
    pk_loja     BIGSERIAL PRIMARY KEY,
    id_loja     INTEGER UNIQUE NOT NULL,
    nome_loja   TEXT    NOT NULL,
    logradouro  TEXT,
    numero      INTEGER,
    bairro      TEXT,
    cidade      TEXT,
    estado      CHAR(2),
    cep         VARCHAR(10)
);
```

---

## 6. Tabela `bronze.vendedores`

```sql
CREATE TABLE IF NOT EXISTS bronze.vendedores (
    pk_vendedor     BIGSERIAL PRIMARY KEY,
    id_vendedor     INTEGER UNIQUE NOT NULL,
    nome_vendedor   TEXT    NOT NULL,
    data_admissao   DATE,
    endereco_vendedor TEXT,
    data_nascimento DATE
);
```
---

## Orquestra√ß√£o com Apache Airflow (sem Docker)

### 1. Defina as vari√°veis de ambiente

```bash
export AIRFLOW_HOME=$(pwd)/airflow
AIRFLOW_VERSION=2.8.1
PYTHON_VERSION=$(python --version | cut -d " " -f2 | cut -d "." -f1,2)
CONSTRAINT_URL="https://raw.githubusercontent.com/apache/airflow/constraints-${AIRFLOW_VERSION}/constraints-${PYTHON_VERSION}.txt"
```

### 2. Instale o Airflow

```bash
pip install "apache-airflow==${AIRFLOW_VERSION}" --constraint "${CONSTRAINT_URL}"
```

### 3. Inicialize o Airflow e crie o usu√°rio

```bash
airflow db init

airflow users create \
  --username admin \
  --firstname Admin \
  --lastname User \
  --role Admin \
  --email admin@example.com \
  --password admin
```

### 4. Inicie o Airflow

Em dois terminais diferentes:

**Terminal 1 ‚Äì Scheduler**
```bash
source .venv/bin/activate
export AIRFLOW_HOME=$(pwd)/airflow
airflow scheduler
```

**Terminal 2 ‚Äì Webserver**
```bash
source .venv/bin/activate
export AIRFLOW_HOME=$(pwd)/airflow
airflow webserver --port 8080
```

Acesse no navegador: [http://localhost:8080](http://localhost:8080)

---

## Execu√ß√£o Local de Gera√ß√£o de Dados (FastAPI)

### 1. Execute o gerador de dados com Uvicorn

```bash
uvicorn gerador_de_dados.api_vendas_batch:app --reload --port 8002
```

---

## Execu√ß√£o com Docker (opcional)

### 1. Login no GitHub Container Registry (GHCR)

```bash
echo <SEU_GITHUB_TOKEN> | docker login ghcr.io -u <SEU_USUARIO_GITHUB> --password-stdin
```

> Gera√ß√£o do token: GitHub > Settings > Developer Settings > Personal Access Tokens  
> Permiss√µes necess√°rias: ‚úÖ `read:packages`

### 2. Subir os containers (Airflow + dbt)

```bash
docker compose --env-file .env up
```

---

## Observa√ß√µes

- O projeto est√° pronto para rodar **Airflow localmente ou via Docker**.
- Recomendado: PostgreSQL como banco de metadados do Airflow em produ√ß√£o.
- O SQLite √© usado aqui apenas para fins educacionais.

---

# üìÅ Estrutura das Tabelas na Camada Bronze

As seguintes tabelas est√£o dispon√≠veis no banco PostgreSQL, no schema `bronze`:

- `vendas`: informa√ß√µes de vendas realizadas.
- `devolucoes`: registros de devolu√ß√µes de vendas.
- `produtos`: cat√°logo de produtos com categoria e impostos.
- `lojas`: dados cadastrais das lojas.
- `vendedores`: cadastro de vendedores e datas importantes.

---

## üîß Configura√ß√£o do dbt (Data Build Tool)

Este projeto utiliza o **dbt** para organizar e transformar os dados da camada bronze at√© a gold. Abaixo est√£o os passos completos para configura√ß√£o e execu√ß√£o:

### 1. Inicializa√ß√£o do Projeto

```bash
dbt init vendas_dw
```

Siga os prompts e selecione o adaptador `Postgres`.

---

### 2. Estrutura Esperada do Projeto

```text
vendas_dw/
‚îú‚îÄ‚îÄ dbt_project.yml
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ bronze/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ vendas.sql
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ devolucoes.sql
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ produtos.sql
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ lojas.sql
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ vendedores.sql
‚îÇ   ‚îú‚îÄ‚îÄ silver/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ fct_vendas.sql
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ fct_devolucoes.sql
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ dim_lojas.sql
‚îÇ   ‚îú‚îÄ‚îÄ gold/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ indicadores_vendas.sql
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ produtos_mais_devolvidos.sql
‚îÇ   ‚îî‚îÄ‚îÄ _sources.yml
```

---

### 3. Configura√ß√£o do Profile

Crie ou edite o arquivo `~/.dbt/profiles.yml`:

```yaml
vendas_dw:
  target: dev
  outputs:
    dev:
      type: postgres
      host: localhost
      user: seu_usuario
      password: sua_senha
      port: 5432
      dbname: seu_banco
      schema: bronze
      threads: 4
```
bash (mover profile.yml)
```
mkdir -p ~/.dbt
code ~/.dbt/profiles.yml
```

---

### testar a conex√£o:
```
dbt debug --project-dir vendas_dw
```

### 4. Registro de Tabelas de Origem

`models/_sources.yml`:

```yaml
version: 2

sources:
  - name: bronze
    database: seu_banco
    schema: bronze
    tables:
      - name: vendas
      - name: devolucoes
      - name: produtos
      - name: lojas
      - name: vendedores
```

---

### 8. Executando o Projeto

Para compilar e rodar os modelos:

```bash
dbt run
```

Para validar a conex√£o e estrutura:

```bash
dbt debug
```

---

---

## üóÇÔ∏è Estrutura de diret√≥rios

```
models/
‚îú‚îÄ sources.yml               # defini√ß√£o das fontes bronze
‚îú‚îÄ silver/
‚îÇ  ‚îú‚îÄ stg_vendas.sql
‚îÇ  ‚îú‚îÄ stg_devolucoes.sql
‚îÇ  ‚îú‚îÄ dim_produtos.sql
‚îÇ  ‚îú‚îÄ dim_lojas.sql
‚îÇ  ‚îî‚îÄ dim_vendedores.sql
‚îî‚îÄ gold/
   ‚îú‚îÄ fct_vendas.sql
   ‚îú‚îÄ fct_devolucoes.sql
   ‚îú‚îÄ mart_receita_diaria_loja.sql
   ‚îî‚îÄ mart_receita_mensal_categoria.sql
```

> **Materializa√ß√£o**  
> - Todos os modelos usam `{{ config(materialized='table') }}`.  
> - Os *schemas* (**bronze**, **silver**, **gold**) s√£o definidos no `project.yaml`.

---

## 1¬† üå± Fonte √∫nica (`sources.yml`)

- **schema**: `bronze`
- **tabelas**: `vendas`, `devolucoes`, `produtos`, `lojas`, `vendedores`

Estas tabelas s√£o carregadas dos CSV/XLSX originais e permanecem **imut√°veis**.

---

## 2¬† ü•à Camada Silver ‚Äî *Staging* e Dimens√µes

| Script | Descri√ß√£o resumida | Entradas | Sa√≠da |
|--------|-------------------|----------|-------|
| **`stg_vendas.sql`** | Normaliza a tabela bruta de vendas. Faz *cast* de tipos, padroniza `meio_pagamento` e garante nomes consistentes. | `bronze.vendas` | `silver.stg_vendas` |
| **`stg_devolucoes.sql`** | Converte tipos e mant√©m coluna `motivo`. | `bronze.devolucoes` | `silver.stg_devolucoes` |
| **`dim_produtos.sql`** | Dimens√£o Produto (id, nome, categoria, % imposto). | `bronze.produtos` | `silver.dim_produtos` |
| **`dim_lojas.sql`** | Dimens√£o Loja (endere√ßos normalizados). | `bronze.lojas` | `silver.dim_lojas` |
| **`dim_vendedores.sql`** | Dimens√£o Vendedor (datas convertidas). | `bronze.vendedores` | `silver.dim_vendedores` |

### 2.1¬† `stg_vendas.sql` ‚Äî detalhes  
| Coluna final | Tipo | Transforma√ß√£o |
|--------------|------|---------------|
| `id_venda` | `BIGINT` | `cast(id_venda as bigint)` |
| `id_produto` | `INT` | ‚Äî |
| `preco` | `NUMERIC(12,2)` | ‚Äî |
| `quantidade` | `INT` | ‚Äî |
| `data_venda` | `DATE` | ‚Äî |
| `id_cliente` | `INT` | ‚Äî |
| `id_loja` | `INT` | ‚Äî |
| `id_vendedor` | `INT` | ‚Äî |
| `meio_pagamento` | `TEXT` | `lower(trim(meio_pagamento))` |
| `parcelamento` | `SMALLINT` | ‚Äî |

*(scripts das dimens√µes seguem padr√£o semelhante de `CAST`, renomea√ß√£o e limpeza de texto)*

---

## 3¬† ü•á Camada Gold ‚Äî Fatos & Marts

| Script | Prop√≥sito | M√©tricas/Transforma√ß√µes | Relacionamentos |
|--------|-----------|-------------------------|-----------------|
| **`fct_vendas.sql`** | Fato granular de vendas. | `receita_bruta = quantidade * preco` + join com dimens√µes. | `id_produto`, `id_loja`, `id_vendedor` |
| **`fct_devolucoes.sql`** | Fato de devolu√ß√µes. | `valor_devolvido = quantidade * preco`. Mant√©m `motivo`. | usa dimens√µes via IDs (opcional) |
| **`mart_receita_diaria_loja.sql`** | Mart operacional: receita di√°ria por loja. | `sum(receita_bruta)`, `count(distinct id_venda)`, `sum(quantidade)`. | deriva de `fct_vendas` |
| **`mart_receita_mensal_categoria.sql`** | Mart t√°tico: receita mensal √ó categoria. | `date_trunc('month', data_venda)` ‚Üí `mes`; `sum(receita_bruta)`. | deriva de `fct_vendas` |

### 3.1¬† `fct_vendas.sql` ‚Äî fluxo simplificado
```mermaid
graph TD
    subgraph Silver
        A(stg_vendas) -->|FK| B(dim_produtos)
        A -->|FK| C(dim_lojas)
        A -->|FK| D(dim_vendedores)
    end
    A -->|JOIN| E(fct_vendas - Gold)
```

### 3.2¬† `mart_receita_diaria_loja.sql`
```sql
select
    data_venda,
    id_loja,
    nome_loja,
    sum(receita_bruta) as receita_diaria,
    count(distinct id_venda) as qtd_vendas,
    sum(quantidade) as itens_vendidos
from {{ ref('fct_vendas') }}
group by data_venda, id_loja, nome_loja;
```
> **Uso**: Pain√©is operacionais (metas di√°rias, comparativo de lojas).

---

## 4¬† üöÄ Execu√ß√£o sugerida para a aula

```bash
# 1) Materializar staging
dbt run --select silver

# 2) Materializar fatos e marts
dbt run --select gold

# 3) Explorar lineage
dbt docs generate
dbt docs serve
```

### T√≥picos para demonstrar
1. **Cast de tipos** e por que isso deve ficar fora do BI.  
2. **Separa√ß√£o de responsabilidade** (bronze imut√°vel, silver conforma, gold agrega).  
3. **Lineage** no dbt Docs: como rastrear colunas.  
4. **Incremental vs. table**: quando trocar materializa√ß√£o.  
5. **Tests**: `unique`/`not_null` em IDs das dimens√µes e fatos.

---

## 5¬† üìå Resumo r√°pido

| Camada | Objetivo | Exemplos |
|--------|----------|----------|
| **Bronze** | Raw, somente ingest√£o. | CSV/XLSX originais. |
| **Silver** | Limpeza, tipagem, PK/FK, conformidade. | `stg_vendas`, `dim_*`. |
| **Gold** | Consum√≠veis por BI, agrega√ß√µes, modelos de neg√≥cio. | `fct_*`, `mart_*`. |

------------------------------------------------------------------------------------------

## üß† Autor

**Walter Gonzaga**  
Data Architect | Engenheiro de Dados | Mentor  
[LinkedIn](https://www.linkedin.com/in/waltergonzaga)

---